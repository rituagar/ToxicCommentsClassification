{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"One can make an analogy in mathematical terms by envisioning the distribution of opinions in a population as a Gaussian curve. We would then say that the consensus would be a statement that represents the range of opinions within perhaps three standard deviations of the mean opinion. sounds arbitrary and ad hoc.  Does it really belong in n encyclopedia article?  I don't see that it adds anything useful.The paragraph that follows seems much more useful.  Are there any political theorists out there who can clarify the issues?  It seems to me that this is an issue that Locke, Rousseau, de Toqueville, and others must have debated...  SR\"]\n",
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "lines = open('data/train.csv', 'r').readlines()\n",
    "lines = lines[1:] #removing the header\n",
    "tokens = []\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for line in lines:\n",
    "    train_data.append(line.split(\"\\t\")[1])\n",
    "    tempLabel = line.split(\"\\t\")[2]\n",
    "    if float(tempLabel)>0.5:\n",
    "        tempLabel = 1.0;\n",
    "    else:\n",
    "        tempLabel = 0.0;\n",
    "    train_labels.append(tempLabel)\n",
    "    # tokens.append(word_tokenize(line))\n",
    "    print(train_data)\n",
    "    print(train_labels)\n",
    "    break;\n",
    "# return [train_data,train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn\n",
    "import numpy as np\n",
    "import ReadData as read\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_data ,train_labels = read.load_data(\"data/train.csv\")\n",
    "dev_data,dev_labels = read.load_data(\"data/dev.csv\")\n",
    "\n",
    "print train_data[1]\n",
    "max_document_length = max([len(x.split(\" \")) for x in train_data])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x_train = np.array(list(vocab_processor.fit_transform(train_data)))\n",
    "\n",
    "x_dev = np.array(list(vocab_processor.fit_transform(dev_data)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
